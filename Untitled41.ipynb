{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPaujNzjePqV",
        "outputId": "0c449b90-76fd-4a99-9c71-af5ab00369ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pennylane\n",
            "  Downloading PennyLane-0.38.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pennylane) (3.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install pennylane"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load R matrix from sinr.csv\n",
        "R_matrix = pd.read_csv('/content/SINR_data.csv', header=None).values\n",
        "\n",
        "# Constants\n",
        "NAP = 4  # Number of access points\n",
        "Nuser = 4  # Number of users\n",
        "Ncloud = 4  # Number of cloud qubits\n",
        "sigma = 0.1\n",
        "pt = 0.5\n",
        "rho = pt / sigma**2\n",
        "shift = np.pi / 4\n",
        "epsilon = 1e-6  # Small value for finite differences\n",
        "\n",
        "# Load and prepare the data\n",
        "data_df = pd.read_csv('/content/H_Matrix_data.csv', header=None)\n",
        "data = data_df.values\n",
        "data = data.reshape((4, 4, 1000))\n",
        "X_data = data.reshape((4*4, 1000)).T\n",
        "Y_data = np.random.rand(1000, 16)  # Dummy labels\n",
        "\n",
        "# Split data into training and validation sets\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_data, Y_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the number of qubits and other parameters for the quantum circuit\n",
        "n_qubits = Ncloud  # using Ncloud as the number of qubits\n",
        "n_layers = 2\n",
        "\n",
        "# Preparing the qubits - default state 0\n",
        "dev = qml.device('default.qubit', wires=n_qubits)\n",
        "\n",
        "# Define the quantum circuit (QNN)\n",
        "@qml.qnode(dev)\n",
        "def quantum_circuit(weights, x):\n",
        "    qml.AngleEmbedding(x, wires=range(n_qubits))  # Encoding inputs or channel matrix\n",
        "    qml.StronglyEntanglingLayers(weights, wires=range(n_qubits))  # Quantum layers\n",
        "    routput = [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
        "    return routput  # Output probabilities\n",
        "\n",
        "def qnn_layer(weights, x):\n",
        "    return quantum_circuit(weights, x)\n",
        "\n",
        "# Define the classical layer function\n",
        "def classical_layer(inputs, weights, biases):\n",
        "    return np.dot(inputs, weights.T) + biases\n",
        "\n",
        "# Hybrid model combining quantum and classical layers\n",
        "def hybrid_model(weights, X):\n",
        "    qnn_outputs = []\n",
        "    for i in range(0, X.shape[1], n_qubits):\n",
        "        x_subset = X[:, i:i + n_qubits]\n",
        "        qnn_output = np.array([qnn_layer(weights, x) for x in x_subset])\n",
        "        qnn_outputs.append(qnn_output)\n",
        "\n",
        "    qnn_output_combined = np.concatenate(qnn_outputs, axis=1)\n",
        "\n",
        "    W1 = np.random.random((64, qnn_output_combined.shape[1]))\n",
        "    b1 = np.zeros((64,))\n",
        "    W2 = np.random.random((16, 64))\n",
        "    b2 = np.zeros((16,))\n",
        "\n",
        "    hidden_output = np.tanh(classical_layer(qnn_output_combined, W1, b1))\n",
        "    output = classical_layer(hidden_output, W2, b2)\n",
        "\n",
        "    return output\n",
        "\n",
        "def loss(weights, X, Y):\n",
        "    predictions = hybrid_model(weights, X)\n",
        "    return np.mean((predictions - Y) ** 2)\n",
        "\n",
        "# Initialize weights for quantum layers\n",
        "weights_shape = qml.StronglyEntanglingLayers.shape(n_layers=n_layers, n_wires=n_qubits)\n",
        "weights = np.random.random(weights_shape)\n",
        "\n",
        "# Use Pennylane's gradient descent optimizer\n",
        "opt = qml.GradientDescentOptimizer(stepsize=0.1)\n",
        "\n",
        "try:\n",
        "    num_epochs = 50\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        weights, cost = opt.step_and_cost(lambda w: loss(w, X_train, Y_train), weights)\n",
        "\n",
        "        if epoch % 150 == 0:\n",
        "            print(f\"\\n--- Intermediate Results at Epoch {epoch} ---\")\n",
        "            print(f\"Cost: {cost}\")\n",
        "\n",
        "    # Validation\n",
        "    val_cost = loss(weights, X_val, Y_val)\n",
        "    print(f\"\\nFinal Validation Cost: {val_cost}\")\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Training interrupted.\")\n",
        "finally:\n",
        "    print(\"Training completed.\")\n",
        "\n",
        "def calculate_qassign(h):\n",
        "    # Compute the assignment policy using pre-loaded R matrix\n",
        "    Qassign = np.sum(R_matrix)\n",
        "    print(\"Qassign:\", Qassign)\n",
        "    return Qassign\n",
        "\n",
        "def calculate_phi_assign(h):\n",
        "    _, s, _ = np.linalg.svd(h)\n",
        "    Phi = np.ones(len(s))\n",
        "    for i in range(len(s)):\n",
        "        if s[i] < -1 / rho:\n",
        "            Phi[i] = float('nan')\n",
        "        else:\n",
        "            Phi[i] = np.log2(1 + (s[i] * rho))\n",
        "    Phi_assign = -np.nansum(Phi)\n",
        "    print(\"phi assign:\", Phi_assign)\n",
        "    return Phi_assign\n",
        "\n",
        "def calculate_lassign(h):\n",
        "    Qassign, _, _ = calculate_qassign(h)\n",
        "    Phi_assign = calculate_phi_assign(h)\n",
        "    Lassign = np.abs(Qassign - Phi_assign)\n",
        "    return Lassign\n",
        "\n",
        "# Define the loss function\n",
        "def loss(weights, X, Y):\n",
        "    predictions = hybrid_model(weights, X)\n",
        "    Lassign_total = 0\n",
        "    for i in range(X.shape[0]):\n",
        "        h_block = X[i:i + 4].reshape((4, 4))\n",
        "        Lassign = calculate_lassign(h_block)\n",
        "        Lassign_total += np.mean((predictions[i] - Y[i]) ** 2) + Lassign\n",
        "    return Lassign_total / X.shape[0]\n",
        "\n",
        "# def loss_resource_allocation(weights, X_train):\n",
        "#     Lassign_total = 0\n",
        "#     num_batches = 0\n",
        "#     batch_size = 10\n",
        "#     for index in range(0, len(X_train), batch_size):\n",
        "#         if index + batch_size > len(X_train):\n",
        "#             continue\n",
        "#         h_block = X_train[index:index + batch_size, :]\n",
        "#         results = hybrid_model(weights, h_block)\n",
        "#         Lassign = calculate_lassign(h_block)\n",
        "#         Lassign_total += Lassign\n",
        "#         num_batches += 1\n",
        "\n",
        "#     if num_batches > 0:\n",
        "#         Lassign_total /= num_batches\n",
        "\n",
        "#     return Lassign_total\n",
        "\n",
        "def optimize(initial_params, X_train, epochs=100, lr=0.01):\n",
        "    params = initial_params\n",
        "    loss_history = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        grad_fn = qml.grad(lambda theta: loss(theta, X_train))\n",
        "        gradients = grad_fn(params)\n",
        "        params = params - lr * gradients\n",
        "        current_loss = loss(params, X_train)\n",
        "        loss_history.append(current_loss)\n",
        "\n",
        "        if epoch % 150 == 0:\n",
        "            print(f\"Epoch {epoch} | Loss: {current_loss}\")\n",
        "\n",
        "    return params, loss_history\n",
        "\n",
        "theta_cloud_initial = np.random.rand(Ncloud)\n",
        "theta_cloud_optimal, loss_history = optimize(theta_cloud_initial, X_train, epochs=100)\n",
        "\n",
        "Qassign_list = []\n",
        "Lassign_list = []\n",
        "\n",
        "for index in range(0, len(X_val), 10):\n",
        "    if index + 10 > len(X_val):\n",
        "        continue\n",
        "    h_block = X_val[index:index + 10, :]\n",
        "    results = hybrid_model(weights, h_block)\n",
        "    print(\"Results:\", results)\n",
        "    Qassign = calculate_qassign(h_block)\n",
        "    Lassign = calculate_lassign(h_block)\n",
        "\n",
        "    Qassign_list.append(Qassign)\n",
        "    Lassign_list.append(Lassign)\n",
        "\n",
        "print(\"Validation Results:\")\n",
        "for i, (Qassign, Lassign) in enumerate(zip(Qassign_list, Lassign_list)):\n",
        "    print(f\"Block {i+1}:\")\n",
        "    print(f\"Lassign: {Lassign}\")\n",
        "    print(f\"Qassign: {Qassign}\")\n"
      ],
      "metadata": {
        "id": "lpwJMErTeSte"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}